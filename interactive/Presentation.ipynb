{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insult Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project by \n",
    "#### Chirag Khurana, Pallavi S. Rawat, Shubham Goyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unprocessed Data\n",
    "# full_df = pd.read_csv('../data/train.csv')\n",
    "# verify_df = pd.read_csv('../data/impermium_verification_labels.csv')\n",
    "# data = full_df.append(verify_df)\n",
    "# data.Comment = [x[1: -1] for x in data.Comment]\n",
    "\n",
    "# Unprocessed Data\n",
    "# full_df = pd.read_csv('../data/train.csv')\n",
    "# verify_df = pd.read_csv('../data/impermium_verification_labels.csv')\n",
    "# pdata_df = full_df.append(verify_df)\n",
    "\n",
    "# Processed Data\n",
    "full_df = pd.read_csv('../data/processed/train.csv')\n",
    "verify_df = pd.read_csv('../data/processed/impermium_verification_labels.csv')\n",
    "pdata_df = full_df.append(verify_df)\n",
    "\n",
    "pdata = pdata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying cleaning stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def sanitize_wo_stopwords(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    s = []\n",
    "    for token in doc:\n",
    "#         print(token.dep_)\n",
    "        if str(token.pos_) != 'SPACE' and not token.is_stop:\n",
    "            s.append(token.text)\n",
    "    return ' '.join(s)\n",
    "\n",
    "def sanitize_with_stopwords(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    s = []\n",
    "    for token in doc:\n",
    "#         print(token.dep_)\n",
    "        if str(token.pos_) != 'SPACE':\n",
    "            s.append(token.text)\n",
    "    return ' '.join(s)\n",
    "\n",
    "\n",
    "def sanitize_with_lemma(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    s = []\n",
    "    for token in doc:\n",
    "#         print(token.dep_)\n",
    "        if str(token.pos_) != 'SPACE':\n",
    "            s.append(token.lemma_)\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence, bad_word_dict):\n",
    "    i = 0;\n",
    "    data = []\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    regex = \"[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\"\n",
    "    regex1 = \"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\"\n",
    "    regex2 = \"(www | http: | https:)+[ ^\\s]+[\\w]\"\n",
    "    z=0\n",
    "    s0 = sentence\n",
    "    s0=s0.lower()\n",
    "    s0 = s0.replace(\"\\\\\\\\n\", \" \")\n",
    "    s0 = s0.replace(\"\\\\n\", \" \")\n",
    "    s0 = s0.replace(\"\\\\t\", \" \")\n",
    "    s0 = s0.replace(\"\\\\\\\\xc2\", \" \")\n",
    "    s0 = s0.replace(\"\\\\\\\\xa0\", \" \")\n",
    "    s0 = s0.replace(\"\\\\\\\\xa0\", \" \")\n",
    "    s0 = s0.replace(\"\\\\[\\\\w]\", ' ')\n",
    "    s0 = re.sub(r\"\\\\[a-zA-Z0-9.]*\", \"\", s0)\n",
    "\n",
    "    s0 = re.sub(\"([a-zA-Z0-9.?!#*])\\\\1\\\\1+\", \"\\\\1\", s0)  # brooooook->brook\n",
    "\n",
    "    s0 = re.sub(regex, \"\", s0)  # url\n",
    "    s0 = re.sub(regex2, \"\", s0)  # http url\n",
    "    s0 = re.sub(regex1, \"\", s0)\n",
    "    s0 = re.sub(cleanr, '', s0)  # html tags\n",
    "\n",
    "    string = \":-/)\"\n",
    "    ###REMOVING SMILEYS\n",
    "    # s0=re.sub(string,\"  smiley\",s0);\n",
    "\n",
    "    ##s0=re.sub(\"\\[\\]+\",\"\",s0)            #remove \\\n",
    "    s0 = s0.strip()\n",
    "    s0 = s0.replace(\" wont \", \" will not \")\n",
    "    s0 = s0.replace(\" won't \", \" will not \")\n",
    "    s0 = s0.replace(\" don't \", \" do not \")\n",
    "    s0 = s0.replace(\" dont \", \" do not \")\n",
    "    s0 = s0.replace(\" dnt \", \" do not \")\n",
    "    s0 = s0.replace(\" didn't \", \" did not \")\n",
    "    s0 = s0.replace(\" didnt \", \" did not \")\n",
    "    s0 = s0.replace(\"Didn't \", \"Did not \")\n",
    "    s0 = s0.replace(\" i'll\", \" I will\")\n",
    "    s0 = s0.replace(\" I'll\", \" I will\")\n",
    "    s0 = s0.replace(\"I'll\", \"I will\")\n",
    "    s0 = s0.replace(\" cant\", \" can not\")\n",
    "    s0 = s0.replace(\" can't\", \" can not\")\n",
    "    s0 = s0.replace(\" shouldn't\", \" should not\")\n",
    "    s0 = s0.replace(\" shouldnt\", \" should not\")\n",
    "    s0 = s0.replace(\" im \", \" i am \")\n",
    "    s0 = s0.replace(\"ain't\", \"is not\")\n",
    "    s0 = s0.replace(\"aint\", \"is not\")\n",
    "    s0 = s0.replace(\"'ll\", \" will\")\n",
    "    s0 = s0.replace(\"'t[. ]\", \" not\")\n",
    "    #s0=s0.replace(\" u \", \" you \")\n",
    "    s0 = s0.replace(\" r \", \" are \")\n",
    "    s0 = s0.replace(\" m \", \" am \")\n",
    "    s0 = s0.replace(\" ur \", \" your \")\n",
    "    s0 = s0.replace(\" u'r \", \" you are \")\n",
    "    # s0 = s0.replace(\" you'r \", \"you are \")\n",
    "    # s0 = s0.replace(\"your \", \"you are \")\n",
    "\n",
    "    s0 = s0.replace(\"'ve\", \" have\")\n",
    "    s0 = s0.replace(\"'s\", \" is\")\n",
    "    s0 = s0.replace(\"'re\", \" are\")\n",
    "    s0 = s0.replace(\"'d\", \" would\")\n",
    "    s0 = re.sub(\"([a-zA-Z0-9.]+)\\\\1\\\\1+\", \" \", s0)  # lolololol->lol\n",
    "    s0 = re.sub(\"[&*?!#^%`~$@]{4}\", \"-TOKEN-\", s0)  # &*$!^@->>>>token\n",
    "    s0 = s0.strip();\n",
    "    # print(\"before       \" + s0)\n",
    "    for key, value in bad_word_dict.items():\n",
    "        sk = s0.replace(\" \"+key,\" \"+value+\" \")\n",
    "        if(sk!=s0):\n",
    "            s0=sk\n",
    "    s0 = re.sub(\"(@|#)[\\w.]*\", \"-PRON-\", s0)  # @username with YOU\n",
    "    return s0\n",
    "\n",
    "bad_dict = None\n",
    "\n",
    "def build_badword_dict():\n",
    "    global bad_dict\n",
    "    badfile = open('../data/misc/ConvertedBadWords.txt')\n",
    "    bad_dict = dict()\n",
    "    for line in badfile:\n",
    "        bw = line.split(',')\n",
    "        if len(bw) == 2:\n",
    "            bad_dict[bw[0]] = bw[1].strip()\n",
    "\n",
    "def sanitize_bw_regx(text):\n",
    "    global bad_dict\n",
    "    if not bad_dict:\n",
    "        build_badword_dict()\n",
    "    return preprocessing(text, bad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.Comment = [x[1: -1] for x in pdata_df.Comment]\n",
    "\n",
    "pdata.Comment = [sanitize_wo_stopwords(x) for x in pdata.Comment]\n",
    "# pdata.Comment = [sanitize_bw_regx(x) for x in pdata.Comment]\n",
    "# pdata.Comment = [sanitize_with_stopwords(x) for x in pdata.Comment]\n",
    "# pdata.Comment = [sanitize_with_lemma(x) for x in pdata.Comment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata_ni = pdata.query('Insult == 0')\n",
    "pdata_i = pdata.query('Insult == 1')\n",
    "pdata_ni.shape, pdata_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptrain_ni, ptest_ni = train_test_split(pdata_ni, test_size=0.6)\n",
    "print(ptrain_ni.shape, ptest_ni.shape)\n",
    "\n",
    "ptrain_i, ptest_i = train_test_split(pdata_i, test_size=0.2)\n",
    "print(ptrain_i.shape, ptest_i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train final model, to show full data\n",
    "\n",
    "# ptrain_ni, ptest_ni = train_test_split(pdata_ni, test_size=0.5)\n",
    "# print(ptrain_ni.shape, ptest_ni.shape)\n",
    "\n",
    "# ptrain_i, ptest_i = train_test_split(pdata_i, test_size=0.05)\n",
    "# print(ptrain_i.shape, ptest_i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(data, test_size=0.2)\n",
    "# ptrain, ptest = train_test_split(pdata, test_size=0.2)\n",
    "ptrain = ptrain_i.append(ptrain_ni)\n",
    "ptest = ptest_i.append(ptest_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = TfidfVectorizer(ngram_range=(1, 3), analyzer='word', use_idf=False, max_features=50000) \n",
    "tfidf_c = TfidfVectorizer(ngram_range=(3, 10), analyzer='char', use_idf=False, max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrain_data_w = tfidf_w.fit_transform(ptrain.Comment)\n",
    "ptrain_data_c = tfidf_c.fit_transform(ptrain.Comment)\n",
    "\n",
    "ptrain_data_w.shape, ptrain_data_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectorizer object\n",
    "\n",
    "# pickle.dump(tfidf_w, open(\"insult_tfidf_w.vectorizer\", \"wb\" ))\n",
    "# pickle.dump(tfidf_c, open(\"insult_tfidf_c.vectorizer\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Insult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mat(mat):\n",
    "    m = []\n",
    "    for i, row in enumerate(mat):\n",
    "        m.append([float(x / sum(row)) for x in row])\n",
    "    return np.array(m)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_nb_w = MultinomialNB(alpha=0.01)\n",
    "insult_nb_w.fit(ptrain_data_w, ptrain.Insult)\n",
    "\n",
    "insult_nb_c = MultinomialNB(alpha=0.01)\n",
    "insult_nb_c.fit(ptrain_data_c, ptrain.Insult)\n",
    "\n",
    "ptest_data_w = tfidf_w.transform(ptest.Comment)\n",
    "ptest_data_c = tfidf_c.transform(ptest.Comment)\n",
    "\n",
    "predicted_nb_w = insult_nb_w.predict(ptest_data_w)\n",
    "predicted_nb_c = insult_nb_c.predict(ptest_data_c)\n",
    "print(np.mean(predicted_nb_w == ptest.Insult), np.mean(predicted_nb_c == ptest.Insult))\n",
    "predicted_nb_w_prob = insult_nb_w.predict_proba(ptest_data_w)\n",
    "predicted_nb_c_prob = insult_nb_c.predict_proba(ptest_data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for NB Classifier on Word - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_w = confusion_matrix(ptest.Insult, predicted_nb_w)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for NB Classifier on Character - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_c = confusion_matrix(ptest.Insult, predicted_nb_c)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_svm_w = LinearSVC()\n",
    "insult_svm_w.fit(ptrain_data_w, ptrain.Insult)\n",
    "\n",
    "insult_svm_c = LinearSVC()\n",
    "insult_svm_c.fit(ptrain_data_c, ptrain.Insult)\n",
    "\n",
    "ptest_data_w = tfidf_w.transform(ptest.Comment)\n",
    "ptest_data_c = tfidf_c.transform(ptest.Comment)\n",
    "\n",
    "predicted_svm_w = insult_svm_w.predict(ptest_data_w)\n",
    "predicted_svm_c = insult_svm_c.predict(ptest_data_c)\n",
    "np.mean(predicted_svm_w == ptest.Insult), np.mean(predicted_svm_c == ptest.Insult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the SVM trained model\n",
    "\n",
    "# pickle.dump(insult_svm_w, open(\"insult_classifier_svm_w.model\", \"wb\" ))\n",
    "# pickle.dump(insult_svm_c, open(\"insult_classifier_svm_c.model\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for SVM Classifier on Word - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_w = confusion_matrix(ptest.Insult, predicted_svm_w)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for SVM Classifier on Character - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_c = confusion_matrix(ptest.Insult, predicted_svm_c)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_lr_w = LogisticRegression()\n",
    "insult_lr_w.fit(ptrain_data_w, ptrain.Insult)\n",
    "\n",
    "insult_lr_c = LogisticRegression()\n",
    "insult_lr_c.fit(ptrain_data_c, ptrain.Insult)\n",
    "\n",
    "ptest_data_w = tfidf_w.transform(ptest.Comment)\n",
    "ptest_data_c = tfidf_c.transform(ptest.Comment)\n",
    "\n",
    "predicted_lr_w = insult_lr_w.predict(ptest_data_w)\n",
    "predicted_lr_c = insult_lr_c.predict(ptest_data_c)\n",
    "print(np.mean(predicted_lr_w == ptest.Insult), np.mean(predicted_lr_c == ptest.Insult))\n",
    "predicted_lr_w_prob = insult_lr_w.predict_proba(ptest_data_w)\n",
    "predicted_lr_c_prob = insult_lr_c.predict_proba(ptest_data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Logistic Regression Classifier on Word - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_w = confusion_matrix(ptest.Insult, predicted_lr_w)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_w, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Logistic Regression Classifier on Character - N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix_c = confusion_matrix(ptest.Insult, predicted_lr_c)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'],\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_c, classes=['Not Insult', 'Insult'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(ptest.Insult, predicted_lr_c_prob[:, 1:])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for insult classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(ptest.Insult, predicted_lr_c_prob[:, 1:]), roc_auc_score(ptest.Insult, predicted_lr_w_prob[:, 1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
